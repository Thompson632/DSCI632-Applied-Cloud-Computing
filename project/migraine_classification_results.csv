model,parameter tuned,data,accuracy,recall,precision,f1-score
Random Forest,impurity = entropy,Train,0.935,0.981,0.968,0.99
Random Forest,impurity = entropy,Test,0.829,0.818,0.963,0.9
Random Forest,"maxDepth = 10, impurity = entropy, numTrees = 25",Train,0.978,0.981,0.983,0.99
Random Forest,"maxDepth = 10, impurity = entropy, numTrees = 25",Test,0.855,0.9,0.935,0.947
Decision Tree,impurity = entropy,Train,0.898,0.962,0.943,0.981
Decision Tree,impurity = entropy,Test,0.776,0.8,0.902,0.842
Decision Tree,"maxDepth = 10, impurity = entropy",Train,0.994,1.0,0.995,1.0
Decision Tree,"maxDepth = 10, impurity = entropy",Test,0.803,0.889,0.823,0.889
Logistic Regression,default,Train,0.978,1.0,0.982,1.0
Logistic Regression,default,Test,0.882,1.0,0.9,0.941
Logistic Regression,maxIter = 1000,Train,0.988,1.0,0.989,1.0
Logistic Regression,maxIter = 1000,Test,0.829,1.0,0.845,0.941
